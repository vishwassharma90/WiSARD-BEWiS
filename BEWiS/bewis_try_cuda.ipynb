{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "import time\n",
    "from numba import njit,jit,prange,vectorize,int32,float64,int64,cuda\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quesize = 20\n",
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 256*3\n",
    "@njit\n",
    "def preprocessing(a):\n",
    "    a = a.copy_to_host()\n",
    "    px_train = a.reshape(input_size)\n",
    "    px_train = np.asarray(px_train).astype(np.int32)\n",
    "\n",
    "    return px_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WiSARDrp:                                 \n",
    "    \n",
    "    def __init__(self,input_size,no_of_rand_pix_selec,nodes,ram_address_count,dis_number):\n",
    "        self.input_size = input_size\n",
    "        self.no_of_rand_pix_selec = no_of_rand_pix_selec\n",
    "        self.nodes = nodes\n",
    "        self.ram_address_count = ram_address_count\n",
    "        self.dis_number = dis_number \n",
    "\n",
    "\n",
    "    def discriminator(self):\n",
    "        discriminator = []\n",
    "        accumulated_pos = []\n",
    "        my_list = list(range(0,self.input_size))\n",
    "        for i in range(self.dis_number):  #10\n",
    "            ram = []\n",
    "            random.shuffle(my_list)\n",
    "            for j in range((int)((self.nodes))): #98    \n",
    "                total_pos = []\n",
    "                positions = []\n",
    "                positions = my_list[j*no_of_rand_pix_selec:j*no_of_rand_pix_selec+no_of_rand_pix_selec]\n",
    "                accumulated_pos.append(positions)\n",
    "                total_pos = np.vstack(positions)\n",
    "                #print(total_pos)\n",
    "                table = []\n",
    "                dictionary = {}\n",
    "                \n",
    "                max = len(\"{0:b}\".format(2**len(total_pos))) - 1\n",
    "                for i in range(2**len(total_pos)):\n",
    "                    x = (('0' * max) + \"{0:b}\".format(i))\n",
    "                    x = x[len(x)-max:]\n",
    "                    dictionary[x] = 0\n",
    "                table.append(dictionary)\n",
    "                #print(table)\n",
    "                ram.append(table)\n",
    "\n",
    "            di = []\n",
    "            for j in range(len(ram)):\n",
    "                for i in range(len(ram[j])):\n",
    "                    for key, value in ram[j][i].items():\n",
    "                        temp = [key,value]\n",
    "                        di.append(temp)\n",
    "                        \n",
    "            discriminator.append(di)\n",
    "    \n",
    "        discriminator = np.asarray(discriminator).astype(np.int32)\n",
    "        accumulated_pos = np.asarray(accumulated_pos).astype(np.int32)\n",
    "        return discriminator, accumulated_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 256*3\n",
    "no_of_rand_pix_selec = 2**(2)     ## ** (must) no_of_rand_pix_selec = 2^(n) where n is 0,1,2...\n",
    "nodes = int(input_size/no_of_rand_pix_selec)    \n",
    "ram_address_count = 2**(no_of_rand_pix_selec)\n",
    "dis_number = 100*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072, 2)\n"
     ]
    }
   ],
   "source": [
    "w = WiSARDrp(input_size,no_of_rand_pix_selec,nodes,ram_address_count,dis_number)\n",
    "d, acc_pos = w.discriminator()\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nInvalid use of Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7ffa88dcca58>) with argument(s) of type(s): (array(int32, 2d, C))\n * parameterized\nIn definition 0:\n    TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'copy_to_host' of type array(int32, 2d, C)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n[1] During: typing of get attribute at <ipython-input-39-16eb8da92389> (4)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n    raised from /home/iss/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/typeinfer.py:861\nIn definition 1:\n    TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'copy_to_host' of type array(int32, 2d, C)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n[1] During: typing of get attribute at <ipython-input-39-16eb8da92389> (4)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n    raised from /home/iss/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/typeinfer.py:861\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\n[1] During: resolving callee type: Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7ffa88dcca58>)\n[2] During: typing of call at <ipython-input-40-6d18b2cf2a07> (115)\n\n\nFile \"<ipython-input-40-6d18b2cf2a07>\", line 115:\ndef bewis(frame,w,ID,stabilityqueue,out,index,d,pos):\n    <source elided>\n            if w[i,j] > k:\n                pixel_train = preprocessing(a)\n                ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6d18b2cf2a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mbewis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstabilityqueue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mno_of_frames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mSpecialize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minvoke\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         '''\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mspecialize\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    774\u001b[0m         argtypes = tuple(\n\u001b[1;32m    775\u001b[0m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             kernel = compile_kernel(self.py_func, argtypes,\n\u001b[0;32m--> 792\u001b[0;31m                                     **self.targetoptions)\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_kernel\u001b[0;34m(pyfunc, args, link, debug, inline, fastmath, extensions, max_registers)\u001b[0m\n\u001b[1;32m     60\u001b[0m def compile_kernel(pyfunc, args, link, debug=False, inline=False,\n\u001b[1;32m     61\u001b[0m                    fastmath=False, extensions=[], max_registers=None):\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllvm_func_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     lib, kernel = cres.target_context.prepare_cuda_kernel(cres.library, fname,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_cuda\u001b[0;34m(pyfunc, return_type, args, debug, inline)\u001b[0m\n\u001b[1;32m     49\u001b[0m                                   \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                                   \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                                   locals={})\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mlibrary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    939\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    940\u001b[0m                               args, return_type, flags, locals)\n\u001b[0;32m--> 941\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \"\"\"\n\u001b[1;32m    871\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_pipelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Early pipeline completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    251\u001b[0m                     \u001b[0;31m# No more fallback pipelines?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0;31m# Go to next fallback pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                     \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mstage_nopython_frontend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                 self.locals)\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypemap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[0;34m(typingctx, interp, args, return_type, locals)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0mtypemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalltypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, raise_errors)\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nInvalid use of Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7ffa88dcca58>) with argument(s) of type(s): (array(int32, 2d, C))\n * parameterized\nIn definition 0:\n    TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'copy_to_host' of type array(int32, 2d, C)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n[1] During: typing of get attribute at <ipython-input-39-16eb8da92389> (4)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n    raised from /home/iss/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/typeinfer.py:861\nIn definition 1:\n    TypingError: Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'copy_to_host' of type array(int32, 2d, C)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n[1] During: typing of get attribute at <ipython-input-39-16eb8da92389> (4)\n\nFile \"<ipython-input-39-16eb8da92389>\", line 4:\ndef preprocessing(a):\n    a = a.copy_to_host()\n    ^\n\n    raised from /home/iss/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/numba/typeinfer.py:861\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\n[1] During: resolving callee type: Function(<numba.cuda.compiler.DeviceFunctionTemplate object at 0x7ffa88dcca58>)\n[2] During: typing of call at <ipython-input-40-6d18b2cf2a07> (115)\n\n\nFile \"<ipython-input-40-6d18b2cf2a07>\", line 115:\ndef bewis(frame,w,ID,stabilityqueue,out,index,d,pos):\n    <source elided>\n            if w[i,j] > k:\n                pixel_train = preprocessing(a)\n                ^\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "@cuda.jit\n",
    "def partdef(part,address_of_that_ram,b,sum_of_ram_output):\n",
    "    start = cuda.grid(1)      # (1) one dimensional thread grid, returns a single value\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    \n",
    "\n",
    "@njit(parallel = True)\n",
    "def test_with_bleaching(d,pos,x_test,y_test):\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    images = x_test\n",
    "    lable = y_test\n",
    "    b=1\n",
    "        \n",
    "    image = images\n",
    "    actual_lable = lable\n",
    "            \n",
    "    ix = actual_lable       \n",
    "    t_ratina = pos[int((nodes*ix)):(int)((nodes*ix+nodes))]\n",
    "                \n",
    "    sum_of_ram_output = 0\n",
    "    dis = d[ix]\n",
    "                \n",
    "    for i in range(int(nodes)):\n",
    "        part = dis[(ram_address_count*i):(ram_address_count*i+ram_address_count)]\n",
    "        ratina_for_one_ram = t_ratina[i]\n",
    "                    \n",
    "        n = []                                                                \n",
    "        for pix in ratina_for_one_ram:\n",
    "            if image[(pix-1)]>=1:\n",
    "                n.append(1)\n",
    "            else:\n",
    "                n.append(0)\n",
    "                    \n",
    "        num = 0\n",
    "        for i in range(no_of_rand_pix_selec):\n",
    "            num = (n[i])*(10**((no_of_rand_pix_selec-1)-i)) + num\n",
    "                    \n",
    "        address_of_that_ram = (int)(num)\n",
    "        \n",
    "        threads_per_block =32\n",
    "        blocks_per_grid = 1\n",
    "        #out_device = cuda.device_array_like(sum_of_ram_output)\n",
    "        for key in range(len(part)):\n",
    "            prt = part[key]\n",
    "            if prt[0] == address_of_that_ram and prt[1]>=b:\n",
    "                sum_of_ram_output += 1\n",
    "        #partdef[blocks_per_grid, threads_per_block](part,address_of_that_ram,b,sum_of_ram_output)\n",
    "        #sum_of_ram_output = out_device.copy_to_host()\n",
    "            \n",
    "    if sum_of_ram_output/nodes >= 0.75:\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "        \n",
    "    return right,wrong                \n",
    "                \n",
    "                \n",
    "\n",
    "@njit\n",
    "def IsFoundinStabilityQueue(stabilityqueue1,i,j,pixel):\n",
    "    stabilityqueue2 = stabilityqueue1\n",
    "    c = cuda.local.array(shape = (quesize,3), dtype = int32)    \n",
    "    #np.zeros((quesize,3),dtype=np.int32) \n",
    "    b = cuda.local.array(shape = (4,3), dtype = int32) \n",
    "    #np.zeros((4,3),dtype=np.int32)\n",
    "    for queueIndex in range(quesize):\n",
    "        queuevalue = np.reshape(stabilityqueue2[i,j,queueIndex,:],(3,1))\n",
    "        if queuevalue[0][0] == pixel[0][0] and  queuevalue[1][0] == pixel[1][0] and  queuevalue[2][0] == pixel[2][0] :\n",
    "            b = np.roll(stabilityqueue2[i,j,:queueIndex+1,:],3) \n",
    "            c[:queueIndex+1] = b\n",
    "            c[queueIndex+2:] = stabilityqueue2[i,j,queueIndex+2:,:]\n",
    "            stabilityqueue2[i,j,:,:] = c\n",
    "            return stabilityqueue2,True\n",
    "    return stabilityqueue2,False\n",
    "    \n",
    "    \n",
    "    \n",
    "#@njit\n",
    "@cuda.jit\n",
    "def bewis(frame,w,ID,stabilityqueue,out,index,d,pos):\n",
    "    start = cuda.grid(1)      # (1) one dimensional thread grid, returns a single value\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(start,frame.shape[0],stride):\n",
    "        for j in range(frame.shape[1]):\n",
    "            r,g,b = frame[i,j,:]\n",
    "            #create binary endoder for each pixel\n",
    "            #a = np.zeros((256,3))\n",
    "            a = cuda.local.array(shape = (256,3), dtype = int32)\n",
    "            a[0:r,0] = 1  \n",
    "            a[0:g,1] = 1\n",
    "            a[0:b,2] = 1\n",
    "            #check if pixel color is in front of stability queue\n",
    "            front = np.reshape(stabilityqueue[i,j,0,:],(3,1)) \n",
    "            pixel = np.reshape(frame[i,j,:],(3,1))\n",
    "            pixel_no = i*10+j\n",
    "            if front[0][0] == pixel[0][0] and  front[1][0] == pixel[1][0] and  front[2][0] == pixel[2][0] :\n",
    "                w[i,j] += ID[i,j]\n",
    "                ID[i,j] += 1\n",
    "            if front[0][0] != pixel[0][0] or  front[1][0] != pixel[1][0] or  front[2][0] != pixel[2][0] :\n",
    "                #stabilityqueue,found = IsFoundinStabilityQueue(stabilityqueue,i,j,pixel)\n",
    "                found = 1\n",
    "                if found:\n",
    "                    ID[i,j] = 1\n",
    "                else:\n",
    "                    stabilityqueue[i,j,:,:] = np.roll(stabilityqueue[i,j,:,:],1)\n",
    "                    stabilityqueue[i,j,0,:]= np.reshape(pixel,(3,))\n",
    "                    w[i,j] = 0\n",
    "                    ID[i,j] = 1\n",
    "\n",
    "            if w[i,j] > k:\n",
    "                pixel_train = preprocessing(a)\n",
    "                B = 50    \n",
    "                images = pixel_train\n",
    "                lable = pixel_no   \n",
    "                image = images\n",
    "                num = lable\n",
    "                all_ram_of_selected_discriminator = d[num]\n",
    "                t_ratina = pos[(int)(nodes*num):(int)(nodes*num+nodes)]\n",
    "            \n",
    "                for inode in range((int)(nodes)):\n",
    "                    part = all_ram_of_selected_discriminator[(ram_address_count*inode):(ram_address_count*inode+ram_address_count)]\n",
    "                    ratina_for_one_ram = t_ratina[inode]\n",
    "                          \n",
    "                    n = []                                                                \n",
    "                    for ix in range(len(ratina_for_one_ram)):\n",
    "                        pix = ratina_for_one_ram[ix]\n",
    "                        if image[(pix-1)]>=1:\n",
    "                            n.append(1)    \n",
    "                        else:\n",
    "                            n.append(0)\n",
    "                \n",
    "                    num = 0\n",
    "                    for ino in range(no_of_rand_pix_selec):\n",
    "                        num = (n[ino])*(10**((no_of_rand_pix_selec-1)-ino)) + num\n",
    "            \n",
    "                    address_of_that_ram = (int)(num)\n",
    "                    for key in range(ram_address_count):\n",
    "                        index = part[key]\n",
    "                        if index[0] == address_of_that_ram and index[1] < B:\n",
    "                            index[1] += 1\n",
    "                        else:\n",
    "                            if index[1] != 0 and index[1] != 0:\n",
    "                                index[1] -= 1\n",
    "                \n",
    "            #reconstruct colors from neurons and write it on BG image\n",
    "            pixel_test = preprocessing(a)\n",
    "            #right=1\n",
    "            #wrong =0\n",
    "            right,wrong = test_with_bleaching(d,acc_pos,pixel_test,pixel_no)\n",
    "            if right:\n",
    "                out[i,j] = 0.\n",
    "            if wrong:\n",
    "                out[i,j] = 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stabilityqueue = np.zeros((100,100,quesize,3),dtype=np.int32)   #240,256  #480,640 for bird video, 720,1280 for E_IP1231_Day_1\n",
    "w = np.zeros((100,100),dtype=np.int32)\n",
    "ID = np.zeros((100,100),dtype=np.int32)\n",
    "cap = cv2.VideoCapture('day.avi')\n",
    "out = np.ones((100,100),dtype=np.float64)\n",
    "index = np.zeros((2,),dtype=np.int32)\n",
    "n = 0\n",
    "no_of_frames = 0\n",
    "start = time.time()\n",
    "\n",
    "while(True):\n",
    "    #for file in glob.glob('/home/iss/project/BEWiS/dataset2014/dataset/baseline/highway/input/*jpg'):\n",
    "    #frame = cv2.imread(file)\n",
    "    ret, frame = cap.read()\n",
    "    #Display the resulting frame\n",
    "      \n",
    "    width = 100\n",
    "    height = 100\n",
    "    dim = (width, height)\n",
    " \n",
    "    # resize image\n",
    "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('frame',resized)\n",
    "    bewis(resized,w,ID,stabilityqueue,out,index,d,acc_pos)\n",
    "    no_of_frames += 1\n",
    "    \n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    erosion = cv2.erode(out,kernel,iterations = 1)\n",
    "    dilation = cv2.dilate(erosion,kernel,iterations = 1)\n",
    "    cv2.imshow('out',dilation)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "end = time.time()\n",
    "time = end - start\n",
    "    \n",
    "fps = no_of_frames/time\n",
    "print(fps)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-73faed129004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
     ]
    }
   ],
   "source": [
    "import pycuda.tools\n",
    "import pycuda.autoinit\n",
    "import numpy\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import pycuda.cumath\n",
    "from pycuda.elementwise import ElementwiseKernel\n",
    "\n",
    "blocks = 64\n",
    "block_size = 128\n",
    "nbr_values = blocks * block_size\n",
    "\n",
    "print (\"Using nbr_values ==\", nbr_values)\n",
    "\n",
    "# Number of iterations for the calculations,\n",
    "# 100 is very quick, 2000000 will take a while\n",
    "n_iter = 100000\n",
    "print (\"Calculating %d iterations\" % (n_iter))\n",
    "\n",
    "# create two timers so we can speed-test each approach\n",
    "start = drv.Event()\n",
    "end = drv.Event()\n",
    "\n",
    "\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void gpusin(float *dest, float *a, int n_iter)\n",
    "{\n",
    "  const int i = blockDim.x*blockIdx.x + threadIdx.x;\n",
    "  for(int n = 0; n < n_iter; n++) {\n",
    "    a[i] = sin(a[i]);\n",
    "  }\n",
    "  dest[i] = a[i];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "gpusin = mod.get_function(\"gpusin\")\n",
    "\n",
    "# create an array of 1s\n",
    "a = numpy.ones(nbr_values).astype(numpy.float32)\n",
    "# create a destination array that will receive the result\n",
    "dest = numpy.zeros_like(a)\n",
    "\n",
    "start.record() # start timing\n",
    "gpusin(drv.Out(dest), drv.In(a), numpy.int32(n_iter), grid=(blocks,1), block=(block_size,1,1))\n",
    "end.record() # end timing\n",
    "# calculate the run length\n",
    "end.synchronize()\n",
    "secs = start.time_till(end)*1e-3\n",
    "print (\"SourceModule time and first three results:\")\n",
    "print (\"%fs, %s\" % (secs, str(dest[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Elementwise SECTION\n",
    "# use an ElementwiseKernel with sin in a for loop all in C call from Python\n",
    "kernel = ElementwiseKernel(\n",
    "   \"float *a, int n_iter\",\n",
    "   \"for(int n = 0; n < n_iter; n++) { a[i] = sin(a[i]);}\",\n",
    "   \"gpusin\")\n",
    "\n",
    "a = numpy.ones(nbr_values).astype(numpy.float32)\n",
    "a_gpu = gpuarray.to_gpu(a)\n",
    "start.record() # start timing\n",
    "kernel(a_gpu, numpy.int(n_iter))\n",
    "end.record() # end timing\n",
    "# calculate the run length\n",
    "end.synchronize()\n",
    "secs = start.time_till(end)*1e-3\n",
    "print \"Elementwise time and first three results:\"\n",
    "print \"%fs, %s\" % (secs, str(a_gpu.get()[:3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Elementwise Python looping SECTION\n",
    "# as Elementwise but the for loop is in Python, not in C\n",
    "kernel = ElementwiseKernel(\n",
    "   \"float *a\",\n",
    "   \"a[i] = sin(a[i]);\",\n",
    "   \"gpusin\")\n",
    "\n",
    "a = numpy.ones(nbr_values).astype(numpy.float32)\n",
    "a_gpu = gpuarray.to_gpu(a)\n",
    "start.record() # start timing\n",
    "for i in range(n_iter):\n",
    "    kernel(a_gpu)\n",
    "end.record() # end timing\n",
    "# calculate the run length\n",
    "end.synchronize()\n",
    "secs = start.time_till(end)*1e-3\n",
    "print \"Elementwise Python looping time and first three results:\"\n",
    "print \"%fs, %s\" % (secs, str(a_gpu.get()[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# GPUArray SECTION\n",
    "# The result is copied back to main memory on each iteration, this is a bottleneck\n",
    "\n",
    "a = numpy.ones(nbr_values).astype(numpy.float32)\n",
    "a_gpu = gpuarray.to_gpu(a)\n",
    "start.record() # start timing\n",
    "for i in range(n_iter):\n",
    "    a_gpu = pycuda.cumath.sin(a_gpu)\n",
    "end.record() # end timing\n",
    "# calculate the run length\n",
    "end.synchronize()\n",
    "secs = start.time_till(end)*1e-3\n",
    "print \"GPUArray time and first three results:\"\n",
    "print \"%fs, %s\" % (secs, str(a_gpu.get()[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# CPU SECTION\n",
    "# use numpy the calculate the result on the CPU for reference\n",
    "\n",
    "a = numpy.ones(nbr_values).astype(numpy.float32)\n",
    "start.record() # start timing\n",
    "start.synchronize()\n",
    "\n",
    "for i in range(n_iter):\n",
    "    a = numpy.sin(a)\n",
    "\n",
    "end.record() # end timing\n",
    "# calculate the run length\n",
    "end.synchronize()\n",
    "secs = start.time_till(end)*1e-3\n",
    "print \"CPU time and first three results:\"\n",
    "print \"%fs, %s\" % (secs, str(a[:3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
